{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c83cc2bb-1779-4248-b164-2169200deae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68322598-e88c-4813-bb47-7a228eb0f168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\Daniele\\\\PycharmProjects\\\\LipNetProve\\\\Dataset\\\\Train'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../Dataset/Train')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f3f5c15-5920-45fd-b5f3-a906da0fc8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for l in os.listdir():\n",
    "    if '.DS_Store' not in l:\n",
    "        os.chdir(l)\n",
    "        for m in os.listdir():\n",
    "            data.append([l+'/'+m, l])\n",
    "        os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42a1237b-71f5-4444-9c78-6e24aabd9f96",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[['a/F04_phrases01_02.jpg', 'a'],\n ['a/F04_phrases01_03.jpg', 'a'],\n ['a/F04_phrases01_04.jpg', 'a'],\n ['a/F04_phrases01_05.jpg', 'a'],\n ['a/F04_phrases01_06.jpg', 'a'],\n ['a/F04_phrases01_07.jpg', 'a'],\n ['a/F05_phrases01_01.jpg', 'a'],\n ['a/F05_phrases01_02.jpg', 'a'],\n ['a/F05_phrases01_03.jpg', 'a'],\n ['a/F05_phrases01_04.jpg', 'a'],\n ['a/F05_phrases01_05.jpg', 'a'],\n ['a/F05_phrases01_06.jpg', 'a'],\n ['a/F05_phrases01_07.jpg', 'a'],\n ['a/F05_phrases01_08.jpg', 'a'],\n ['a/F05_phrases01_09.jpg', 'a'],\n ['a/F05_phrases01_10.jpg', 'a'],\n ['a/F06_phrases01_01.jpg', 'a'],\n ['a/F06_phrases01_02.jpg', 'a'],\n ['a/F06_phrases01_03.jpg', 'a'],\n ['a/F06_phrases01_04.jpg', 'a'],\n ['a/F06_phrases01_05.jpg', 'a'],\n ['a/F06_phrases01_07.jpg', 'a'],\n ['a/F06_phrases01_08.jpg', 'a'],\n ['a/F06_phrases01_09.jpg', 'a'],\n ['a/F06_phrases01_10.jpg', 'a'],\n ['a/F07_phrases01_01.jpg', 'a'],\n ['a/F07_phrases01_02.jpg', 'a'],\n ['a/F07_phrases01_03.jpg', 'a'],\n ['a/F07_phrases01_04.jpg', 'a'],\n ['a/F07_phrases01_05.jpg', 'a'],\n ['a/F08_phrases01_04.jpg', 'a'],\n ['a/F08_phrases01_05.jpg', 'a'],\n ['a/F08_phrases01_06.jpg', 'a'],\n ['a/F08_phrases01_07.jpg', 'a'],\n ['a/F08_phrases01_08.jpg', 'a'],\n ['a/F08_phrases01_09.jpg', 'a'],\n ['a/F08_phrases01_10.jpg', 'a'],\n ['a/F09_phrases01_01.jpg', 'a'],\n ['a/F09_phrases01_02.jpg', 'a'],\n ['a/F09_phrases01_03.jpg', 'a'],\n ['a/F09_phrases01_04.jpg', 'a'],\n ['a/F09_phrases01_05.jpg', 'a'],\n ['a/F09_phrases01_06.jpg', 'a'],\n ['a/F09_phrases01_09.jpg', 'a'],\n ['a/F09_phrases01_10.jpg', 'a'],\n ['a/F10_phrases01_01.jpg', 'a'],\n ['a/F10_phrases01_02.jpg', 'a'],\n ['a/F10_phrases01_03.jpg', 'a'],\n ['a/F10_phrases01_04.jpg', 'a'],\n ['a/F10_phrases01_05.jpg', 'a'],\n ['a/F10_phrases01_06.jpg', 'a'],\n ['a/F10_phrases01_07.jpg', 'a'],\n ['a/F10_phrases01_08.jpg', 'a'],\n ['a/F10_phrases01_09.jpg', 'a'],\n ['a/F10_phrases01_10.jpg', 'a'],\n ['a/F11_phrases01_01.jpg', 'a'],\n ['a/F11_phrases01_02.jpg', 'a'],\n ['a/F11_phrases01_03.jpg', 'a'],\n ['a/F11_phrases01_04.jpg', 'a'],\n ['a/F11_phrases01_05.jpg', 'a'],\n ['a/F11_phrases01_06.jpg', 'a'],\n ['a/F11_phrases01_07.jpg', 'a'],\n ['a/F11_phrases01_08.jpg', 'a'],\n ['a/F11_phrases01_09.jpg', 'a'],\n ['a/F11_phrases01_10.jpg', 'a'],\n ['a/M01_phrases01_01.jpg', 'a'],\n ['a/M01_phrases01_02.jpg', 'a'],\n ['a/M01_phrases01_03.jpg', 'a'],\n ['a/M01_phrases01_04.jpg', 'a'],\n ['a/M01_phrases01_05.jpg', 'a'],\n ['a/M01_phrases01_06.jpg', 'a'],\n ['a/M01_phrases01_07.jpg', 'a'],\n ['a/M01_phrases01_08.jpg', 'a'],\n ['a/M01_phrases01_09.jpg', 'a'],\n ['a/M01_phrases01_10.jpg', 'a'],\n ['a/M02_phrases01_01.jpg', 'a'],\n ['a/M02_phrases01_02.jpg', 'a'],\n ['a/M02_phrases01_03.jpg', 'a'],\n ['a/M02_phrases01_04.jpg', 'a'],\n ['a/M02_phrases01_05.jpg', 'a'],\n ['a/M02_phrases01_06.jpg', 'a'],\n ['a/M02_phrases01_07.jpg', 'a'],\n ['a/M02_phrases01_08.jpg', 'a'],\n ['a/M02_phrases01_09.jpg', 'a'],\n ['a/M02_phrases01_10.jpg', 'a'],\n ['a/M04_phrases01_01.jpg', 'a'],\n ['a/M04_phrases01_02.jpg', 'a'],\n ['a/M04_phrases01_03.jpg', 'a'],\n ['a/M04_phrases01_04.jpg', 'a'],\n ['a/M04_phrases01_05.jpg', 'a'],\n ['a/M04_phrases01_06.jpg', 'a'],\n ['a/M04_phrases01_07.jpg', 'a'],\n ['a/M04_phrases01_08.jpg', 'a'],\n ['a/M04_phrases01_09.jpg', 'a'],\n ['a/M04_phrases01_10.jpg', 'a'],\n ['a/M07_phrases01_01.jpg', 'a'],\n ['a/M07_phrases01_02.jpg', 'a'],\n ['a/M07_phrases01_03.jpg', 'a'],\n ['a/M07_phrases01_04.jpg', 'a'],\n ['a/M07_phrases01_05.jpg', 'a'],\n ['a/M07_phrases01_06.jpg', 'a'],\n ['a/M07_phrases01_07.jpg', 'a'],\n ['a/M07_phrases01_08.jpg', 'a'],\n ['a/M07_phrases01_09.jpg', 'a'],\n ['a/M07_phrases01_10.jpg', 'a'],\n ['a/M08_phrases01_01.jpg', 'a'],\n ['a/M08_phrases01_02.jpg', 'a'],\n ['a/M08_phrases01_03.jpg', 'a'],\n ['a/M08_phrases01_04.jpg', 'a'],\n ['a/M08_phrases01_05.jpg', 'a'],\n ['a/M08_phrases01_06.jpg', 'a'],\n ['a/M08_phrases01_07.jpg', 'a'],\n ['a/M08_phrases01_08.jpg', 'a'],\n ['a/M08_phrases01_09.jpg', 'a'],\n ['a/M08_phrases01_10.jpg', 'a'],\n ['b/F01_phrases02_01.jpg', 'b'],\n ['b/F01_phrases02_02.jpg', 'b'],\n ['b/F01_phrases02_03.jpg', 'b'],\n ['b/F01_phrases02_04.jpg', 'b'],\n ['b/F01_phrases02_05.jpg', 'b'],\n ['b/F01_phrases02_06.jpg', 'b'],\n ['b/F01_phrases02_07.jpg', 'b'],\n ['b/F02_phrases02_05.jpg', 'b'],\n ['b/F02_phrases02_06.jpg', 'b'],\n ['b/F02_phrases02_07.jpg', 'b'],\n ['b/F02_phrases02_08.jpg', 'b'],\n ['b/F02_phrases02_09.jpg', 'b'],\n ['b/F02_phrases02_10.jpg', 'b'],\n ['b/F04_phrases02_01.jpg', 'b'],\n ['b/F04_phrases02_02.jpg', 'b'],\n ['b/F04_phrases02_03.jpg', 'b'],\n ['b/F04_phrases02_04.jpg', 'b'],\n ['b/F04_phrases02_05.jpg', 'b'],\n ['b/F04_phrases02_06.jpg', 'b'],\n ['b/F05_phrases02_02.jpg', 'b'],\n ['b/F05_phrases02_06.jpg', 'b'],\n ['b/F05_phrases02_07.jpg', 'b'],\n ['b/F05_phrases02_08.jpg', 'b'],\n ['b/F06_phrases02_02.jpg', 'b'],\n ['b/F06_phrases02_03.jpg', 'b'],\n ['b/F06_phrases02_04.jpg', 'b'],\n ['b/F06_phrases02_05.jpg', 'b'],\n ['b/F06_phrases02_06.jpg', 'b'],\n ['b/F06_phrases02_09.jpg', 'b'],\n ['b/F06_phrases02_10.jpg', 'b'],\n ['b/F07_phrases02_01.jpg', 'b'],\n ['b/F07_phrases02_02.jpg', 'b'],\n ['b/F07_phrases02_03.jpg', 'b'],\n ['b/F07_phrases02_04.jpg', 'b'],\n ['b/F07_phrases02_05.jpg', 'b'],\n ['b/F07_phrases02_06.jpg', 'b'],\n ['b/F07_phrases02_07.jpg', 'b'],\n ['b/F07_phrases02_08.jpg', 'b'],\n ['b/F07_phrases02_09.jpg', 'b'],\n ['b/F07_phrases02_10.jpg', 'b'],\n ['b/F08_phrases02_01.jpg', 'b'],\n ['b/F08_phrases02_02.jpg', 'b'],\n ['b/F08_phrases02_03.jpg', 'b'],\n ['b/F08_phrases02_04.jpg', 'b'],\n ['b/F08_phrases02_05.jpg', 'b'],\n ['b/F08_phrases02_06.jpg', 'b'],\n ['b/F08_phrases02_07.jpg', 'b'],\n ['b/F08_phrases02_08.jpg', 'b'],\n ['b/F08_phrases02_09.jpg', 'b'],\n ['b/F08_phrases02_10.jpg', 'b'],\n ['b/F09_phrases02_01.jpg', 'b'],\n ['b/F09_phrases02_02.jpg', 'b'],\n ['b/F09_phrases02_03.jpg', 'b'],\n ['b/F09_phrases02_04.jpg', 'b'],\n ['b/F09_phrases02_05.jpg', 'b'],\n ['b/F09_phrases02_06.jpg', 'b'],\n ['b/F09_phrases02_07.jpg', 'b'],\n ['b/F09_phrases02_08.jpg', 'b'],\n ['b/F09_phrases02_09.jpg', 'b'],\n ['b/F09_phrases02_10.jpg', 'b'],\n ['b/F10_phrases02_01.jpg', 'b'],\n ['b/F10_phrases02_02.jpg', 'b'],\n ['b/F10_phrases02_03.jpg', 'b'],\n ['b/F10_phrases02_04.jpg', 'b'],\n ['b/F10_phrases02_05.jpg', 'b'],\n ['b/F10_phrases02_06.jpg', 'b'],\n ['b/F10_phrases02_07.jpg', 'b'],\n ['b/F10_phrases02_08.jpg', 'b'],\n ['b/F10_phrases02_09.jpg', 'b'],\n ['b/F10_phrases02_10.jpg', 'b'],\n ['b/F11_phrases02_01.jpg', 'b'],\n ['b/F11_phrases02_02.jpg', 'b'],\n ['b/F11_phrases02_03.jpg', 'b'],\n ['b/F11_phrases02_04.jpg', 'b'],\n ['b/F11_phrases02_05.jpg', 'b'],\n ['b/F11_phrases02_06.jpg', 'b'],\n ['b/F11_phrases02_07.jpg', 'b'],\n ['b/F11_phrases02_08.jpg', 'b'],\n ['b/F11_phrases02_09.jpg', 'b'],\n ['b/F11_phrases02_10.jpg', 'b'],\n ['b/M01_phrases02_01.jpg', 'b'],\n ['b/M01_phrases02_02.jpg', 'b'],\n ['b/M01_phrases02_03.jpg', 'b'],\n ['b/M01_phrases02_04.jpg', 'b'],\n ['b/M01_phrases02_05.jpg', 'b'],\n ['b/M01_phrases02_06.jpg', 'b'],\n ['b/M01_phrases02_07.jpg', 'b'],\n ['b/M01_phrases02_08.jpg', 'b'],\n ['b/M01_phrases02_09.jpg', 'b'],\n ['b/M01_phrases02_10.jpg', 'b'],\n ['b/M02_phrases02_01.jpg', 'b'],\n ['b/M02_phrases02_02.jpg', 'b'],\n ['b/M02_phrases02_03.jpg', 'b'],\n ['b/M02_phrases02_04.jpg', 'b'],\n ['b/M02_phrases02_05.jpg', 'b'],\n ['b/M02_phrases02_06.jpg', 'b'],\n ['b/M02_phrases02_07.jpg', 'b'],\n ['b/M02_phrases02_08.jpg', 'b'],\n ['b/M02_phrases02_09.jpg', 'b'],\n ['b/M02_phrases02_10.jpg', 'b'],\n ['b/M04_phrases02_01.jpg', 'b'],\n ['b/M04_phrases02_02.jpg', 'b'],\n ['b/M04_phrases02_03.jpg', 'b'],\n ['b/M04_phrases02_04.jpg', 'b'],\n ['b/M04_phrases02_05.jpg', 'b'],\n ['b/M04_phrases02_06.jpg', 'b'],\n ['b/M04_phrases02_07.jpg', 'b'],\n ['b/M04_phrases02_08.jpg', 'b'],\n ['b/M04_phrases02_09.jpg', 'b'],\n ['b/M04_phrases02_10.jpg', 'b'],\n ['b/M07_phrases02_01.jpg', 'b'],\n ['b/M07_phrases02_02.jpg', 'b'],\n ['b/M07_phrases02_03.jpg', 'b'],\n ['b/M07_phrases02_04.jpg', 'b'],\n ['b/M07_phrases02_05.jpg', 'b'],\n ['b/M07_phrases02_06.jpg', 'b'],\n ['b/M07_phrases02_07.jpg', 'b'],\n ['b/M07_phrases02_08.jpg', 'b'],\n ['b/M07_phrases02_09.jpg', 'b'],\n ['b/M07_phrases02_10.jpg', 'b'],\n ['b/M08_phrases02_01.jpg', 'b'],\n ['b/M08_phrases02_02.jpg', 'b'],\n ['b/M08_phrases02_03.jpg', 'b'],\n ['b/M08_phrases02_04.jpg', 'b'],\n ['b/M08_phrases02_05.jpg', 'b'],\n ['b/M08_phrases02_06.jpg', 'b'],\n ['b/M08_phrases02_07.jpg', 'b'],\n ['b/M08_phrases02_08.jpg', 'b'],\n ['b/M08_phrases02_09.jpg', 'b'],\n ['b/M08_phrases02_10.jpg', 'b'],\n ['c/F01_phrases03_01.jpg', 'c'],\n ['c/F01_phrases03_02.jpg', 'c'],\n ['c/F01_phrases03_03.jpg', 'c'],\n ['c/F01_phrases03_04.jpg', 'c'],\n ['c/F01_phrases03_05.jpg', 'c'],\n ['c/F01_phrases03_06.jpg', 'c'],\n ['c/F01_phrases03_07.jpg', 'c'],\n ['c/F01_phrases03_08.jpg', 'c'],\n ['c/F01_phrases03_09.jpg', 'c'],\n ['c/F01_phrases03_10.jpg', 'c'],\n ['c/F02_phrases03_01.jpg', 'c'],\n ['c/F02_phrases03_02.jpg', 'c'],\n ['c/F02_phrases03_03.jpg', 'c'],\n ['c/F02_phrases03_04.jpg', 'c'],\n ['c/F02_phrases03_05.jpg', 'c'],\n ['c/F02_phrases03_06.jpg', 'c'],\n ['c/F02_phrases03_07.jpg', 'c'],\n ['c/F02_phrases03_08.jpg', 'c'],\n ['c/F02_phrases03_09.jpg', 'c'],\n ['c/F02_phrases03_10.jpg', 'c'],\n ['c/F05_phrases03_01.jpg', 'c'],\n ['c/F05_phrases03_02.jpg', 'c'],\n ['c/F05_phrases03_03.jpg', 'c'],\n ['c/F05_phrases03_04.jpg', 'c'],\n ['c/F05_phrases03_05.jpg', 'c'],\n ['c/F05_phrases03_06.jpg', 'c'],\n ['c/F05_phrases03_07.jpg', 'c'],\n ['c/F05_phrases03_08.jpg', 'c'],\n ['c/F05_phrases03_09.jpg', 'c'],\n ['c/F05_phrases03_10.jpg', 'c'],\n ['c/F06_phrases03_01.jpg', 'c'],\n ['c/F06_phrases03_02.jpg', 'c'],\n ['c/F06_phrases03_03.jpg', 'c'],\n ['c/F06_phrases03_04.jpg', 'c'],\n ['c/F06_phrases03_05.jpg', 'c'],\n ['c/F06_phrases03_06.jpg', 'c'],\n ['c/F06_phrases03_07.jpg', 'c'],\n ['c/F06_phrases03_08.jpg', 'c'],\n ['c/F06_phrases03_09.jpg', 'c'],\n ['c/F06_phrases03_10.jpg', 'c'],\n ['c/F07_phrases03_01.jpg', 'c'],\n ['c/F07_phrases03_02.jpg', 'c'],\n ['c/F07_phrases03_03.jpg', 'c'],\n ['c/F07_phrases03_04.jpg', 'c'],\n ['c/F07_phrases03_05.jpg', 'c'],\n ['c/F07_phrases03_06.jpg', 'c'],\n ['c/F07_phrases03_07.jpg', 'c'],\n ['c/F07_phrases03_08.jpg', 'c'],\n ['c/F07_phrases03_09.jpg', 'c'],\n ['c/F07_phrases03_10.jpg', 'c'],\n ['c/F08_phrases03_01.jpg', 'c'],\n ['c/F08_phrases03_02.jpg', 'c'],\n ['c/F08_phrases03_03.jpg', 'c'],\n ['c/F08_phrases03_04.jpg', 'c'],\n ['c/F08_phrases03_05.jpg', 'c'],\n ['c/F08_phrases03_06.jpg', 'c'],\n ['c/F08_phrases03_07.jpg', 'c'],\n ['c/F08_phrases03_08.jpg', 'c'],\n ['c/F08_phrases03_09.jpg', 'c'],\n ['c/F08_phrases03_10.jpg', 'c'],\n ['c/F09_phrases03_01.jpg', 'c'],\n ['c/F09_phrases03_02.jpg', 'c'],\n ['c/F09_phrases03_03.jpg', 'c'],\n ['c/F09_phrases03_04.jpg', 'c'],\n ['c/F09_phrases03_05.jpg', 'c'],\n ['c/F09_phrases03_06.jpg', 'c'],\n ['c/F09_phrases03_07.jpg', 'c'],\n ['c/F09_phrases03_08.jpg', 'c'],\n ['c/F09_phrases03_09.jpg', 'c'],\n ['c/F09_phrases03_10.jpg', 'c'],\n ['c/F10_phrases03_01.jpg', 'c'],\n ['c/F10_phrases03_02.jpg', 'c'],\n ['c/F10_phrases03_03.jpg', 'c'],\n ['c/F10_phrases03_04.jpg', 'c'],\n ['c/F10_phrases03_05.jpg', 'c'],\n ['c/F10_phrases03_06.jpg', 'c'],\n ['c/F10_phrases03_07.jpg', 'c'],\n ['c/F10_phrases03_08.jpg', 'c'],\n ['c/F10_phrases03_09.jpg', 'c'],\n ['c/F10_phrases03_10.jpg', 'c'],\n ['c/F11_phrases03_01.jpg', 'c'],\n ['c/F11_phrases03_02.jpg', 'c'],\n ['c/F11_phrases03_03.jpg', 'c'],\n ['c/F11_phrases03_04.jpg', 'c'],\n ['c/F11_phrases03_05.jpg', 'c'],\n ['c/F11_phrases03_06.jpg', 'c'],\n ['c/F11_phrases03_07.jpg', 'c'],\n ['c/F11_phrases03_08.jpg', 'c'],\n ['c/F11_phrases03_09.jpg', 'c'],\n ['c/F11_phrases03_10.jpg', 'c'],\n ['c/M01_phrases03_01.jpg', 'c'],\n ['c/M01_phrases03_02.jpg', 'c'],\n ['c/M01_phrases03_03.jpg', 'c'],\n ['c/M01_phrases03_04.jpg', 'c'],\n ['c/M01_phrases03_05.jpg', 'c'],\n ['c/M01_phrases03_06.jpg', 'c'],\n ['c/M01_phrases03_07.jpg', 'c'],\n ['c/M01_phrases03_08.jpg', 'c'],\n ['c/M01_phrases03_09.jpg', 'c'],\n ['c/M01_phrases03_10.jpg', 'c'],\n ['c/M02_phrases03_01.jpg', 'c'],\n ['c/M02_phrases03_02.jpg', 'c'],\n ['c/M02_phrases03_03.jpg', 'c'],\n ['c/M02_phrases03_04.jpg', 'c'],\n ['c/M02_phrases03_05.jpg', 'c'],\n ['c/M02_phrases03_06.jpg', 'c'],\n ['c/M02_phrases03_07.jpg', 'c'],\n ['c/M04_phrases03_01.jpg', 'c'],\n ['c/M04_phrases03_02.jpg', 'c'],\n ['c/M04_phrases03_03.jpg', 'c'],\n ['c/M04_phrases03_04.jpg', 'c'],\n ['c/M04_phrases03_05.jpg', 'c'],\n ['c/M04_phrases03_06.jpg', 'c'],\n ['c/M04_phrases03_07.jpg', 'c'],\n ['c/M04_phrases03_08.jpg', 'c'],\n ['c/M04_phrases03_09.jpg', 'c'],\n ['c/M04_phrases03_10.jpg', 'c'],\n ['c/M07_phrases03_01.jpg', 'c'],\n ['c/M07_phrases03_02.jpg', 'c'],\n ['c/M07_phrases03_03.jpg', 'c'],\n ['c/M07_phrases03_04.jpg', 'c'],\n ['c/M07_phrases03_05.jpg', 'c'],\n ['c/M07_phrases03_06.jpg', 'c'],\n ['c/M07_phrases03_07.jpg', 'c'],\n ['c/M07_phrases03_08.jpg', 'c'],\n ['c/M08_phrases03_06.jpg', 'c'],\n ['c/M08_phrases03_07.jpg', 'c'],\n ['c/M08_phrases03_08.jpg', 'c'],\n ['c/M08_phrases03_09.jpg', 'c'],\n ['c/M08_phrases03_10.jpg', 'c'],\n ['d/F01_phrases04_01.jpg', 'd'],\n ['d/F01_phrases04_02.jpg', 'd'],\n ['d/F01_phrases04_03.jpg', 'd'],\n ['d/F01_phrases04_04.jpg', 'd'],\n ['d/F01_phrases04_05.jpg', 'd'],\n ['d/F01_phrases04_06.jpg', 'd'],\n ['d/F01_phrases04_07.jpg', 'd'],\n ['d/F01_phrases04_08.jpg', 'd'],\n ['d/F01_phrases04_09.jpg', 'd'],\n ['d/F01_phrases04_10.jpg', 'd'],\n ['d/F02_phrases04_01.jpg', 'd'],\n ['d/F02_phrases04_02.jpg', 'd'],\n ['d/F02_phrases04_03.jpg', 'd'],\n ['d/F02_phrases04_04.jpg', 'd'],\n ['d/F02_phrases04_05.jpg', 'd'],\n ['d/F02_phrases04_06.jpg', 'd'],\n ['d/F02_phrases04_07.jpg', 'd'],\n ['d/F02_phrases04_08.jpg', 'd'],\n ['d/F02_phrases04_09.jpg', 'd'],\n ['d/F02_phrases04_10.jpg', 'd'],\n ['d/F04_phrases04_01.jpg', 'd'],\n ['d/F04_phrases04_02.jpg', 'd'],\n ['d/F04_phrases04_03.jpg', 'd'],\n ['d/F04_phrases04_04.jpg', 'd'],\n ['d/F04_phrases04_05.jpg', 'd'],\n ['d/F04_phrases04_06.jpg', 'd'],\n ['d/F04_phrases04_07.jpg', 'd'],\n ['d/F04_phrases04_08.jpg', 'd'],\n ['d/F04_phrases04_09.jpg', 'd'],\n ['d/F04_phrases04_10.jpg', 'd'],\n ['d/F05_phrases04_01.jpg', 'd'],\n ['d/F05_phrases04_02.jpg', 'd'],\n ['d/F05_phrases04_03.jpg', 'd'],\n ['d/F05_phrases04_04.jpg', 'd'],\n ['d/F05_phrases04_05.jpg', 'd'],\n ['d/F05_phrases04_06.jpg', 'd'],\n ['d/F05_phrases04_07.jpg', 'd'],\n ['d/F05_phrases04_08.jpg', 'd'],\n ['d/F05_phrases04_09.jpg', 'd'],\n ['d/F05_phrases04_10.jpg', 'd'],\n ['d/F06_phrases04_01.jpg', 'd'],\n ['d/F06_phrases04_02.jpg', 'd'],\n ['d/F06_phrases04_03.jpg', 'd'],\n ['d/F06_phrases04_04.jpg', 'd'],\n ['d/F06_phrases04_05.jpg', 'd'],\n ['d/F06_phrases04_06.jpg', 'd'],\n ['d/F06_phrases04_07.jpg', 'd'],\n ['d/F06_phrases04_08.jpg', 'd'],\n ['d/F06_phrases04_09.jpg', 'd'],\n ['d/F06_phrases04_10.jpg', 'd'],\n ['d/F07_phrases04_01.jpg', 'd'],\n ['d/F07_phrases04_02.jpg', 'd'],\n ['d/F07_phrases04_03.jpg', 'd'],\n ['d/F07_phrases04_04.jpg', 'd'],\n ['d/F07_phrases04_05.jpg', 'd'],\n ['d/F07_phrases04_06.jpg', 'd'],\n ['d/F07_phrases04_07.jpg', 'd'],\n ['d/F07_phrases04_08.jpg', 'd'],\n ['d/F07_phrases04_09.jpg', 'd'],\n ['d/F07_phrases04_10.jpg', 'd'],\n ['d/F08_phrases04_01.jpg', 'd'],\n ['d/F08_phrases04_02.jpg', 'd'],\n ['d/F08_phrases04_03.jpg', 'd'],\n ['d/F08_phrases04_04.jpg', 'd'],\n ['d/F08_phrases04_05.jpg', 'd'],\n ['d/F08_phrases04_06.jpg', 'd'],\n ['d/F08_phrases04_07.jpg', 'd'],\n ['d/F08_phrases04_08.jpg', 'd'],\n ['d/F08_phrases04_09.jpg', 'd'],\n ['d/F08_phrases04_10.jpg', 'd'],\n ['d/F09_phrases04_01.jpg', 'd'],\n ['d/F09_phrases04_02.jpg', 'd'],\n ['d/F09_phrases04_03.jpg', 'd'],\n ['d/F09_phrases04_04.jpg', 'd'],\n ['d/F09_phrases04_05.jpg', 'd'],\n ['d/F09_phrases04_06.jpg', 'd'],\n ['d/F09_phrases04_07.jpg', 'd'],\n ['d/F09_phrases04_08.jpg', 'd'],\n ['d/F09_phrases04_09.jpg', 'd'],\n ['d/F09_phrases04_10.jpg', 'd'],\n ['d/F10_phrases04_01.jpg', 'd'],\n ['d/F10_phrases04_02.jpg', 'd'],\n ['d/F10_phrases04_03.jpg', 'd'],\n ['d/F10_phrases04_04.jpg', 'd'],\n ['d/F10_phrases04_05.jpg', 'd'],\n ['d/F10_phrases04_06.jpg', 'd'],\n ['d/F10_phrases04_07.jpg', 'd'],\n ['d/F10_phrases04_08.jpg', 'd'],\n ['d/F10_phrases04_09.jpg', 'd'],\n ['d/F10_phrases04_10.jpg', 'd'],\n ['d/F11_phrases04_01.jpg', 'd'],\n ['d/F11_phrases04_02.jpg', 'd'],\n ['d/F11_phrases04_03.jpg', 'd'],\n ['d/F11_phrases04_04.jpg', 'd'],\n ['d/F11_phrases04_05.jpg', 'd'],\n ['d/F11_phrases04_06.jpg', 'd'],\n ['d/F11_phrases04_07.jpg', 'd'],\n ['d/F11_phrases04_08.jpg', 'd'],\n ['d/F11_phrases04_09.jpg', 'd'],\n ['d/F11_phrases04_10.jpg', 'd'],\n ['d/M01_phrases04_01.jpg', 'd'],\n ['d/M01_phrases04_02.jpg', 'd'],\n ['d/M01_phrases04_03.jpg', 'd'],\n ['d/M01_phrases04_04.jpg', 'd'],\n ['d/M01_phrases04_05.jpg', 'd'],\n ['d/M01_phrases04_06.jpg', 'd'],\n ['d/M01_phrases04_07.jpg', 'd'],\n ['d/M01_phrases04_08.jpg', 'd'],\n ['d/M01_phrases04_09.jpg', 'd'],\n ['d/M01_phrases04_10.jpg', 'd'],\n ['d/M02_phrases04_01.jpg', 'd'],\n ['d/M02_phrases04_02.jpg', 'd'],\n ['d/M02_phrases04_03.jpg', 'd'],\n ['d/M02_phrases04_04.jpg', 'd'],\n ['d/M02_phrases04_05.jpg', 'd'],\n ['d/M02_phrases04_06.jpg', 'd'],\n ['d/M02_phrases04_07.jpg', 'd'],\n ['d/M02_phrases04_08.jpg', 'd'],\n ['d/M02_phrases04_09.jpg', 'd'],\n ['d/M02_phrases04_10.jpg', 'd'],\n ['d/M04_phrases04_01.jpg', 'd'],\n ['d/M04_phrases04_02.jpg', 'd'],\n ['d/M04_phrases04_03.jpg', 'd'],\n ['d/M04_phrases04_04.jpg', 'd'],\n ['d/M04_phrases04_05.jpg', 'd'],\n ['d/M04_phrases04_06.jpg', 'd'],\n ['d/M08_phrases04_07.jpg', 'd'],\n ['d/M08_phrases04_08.jpg', 'd'],\n ['d/M08_phrases04_09.jpg', 'd'],\n ['d/M08_phrases04_10.jpg', 'd'],\n ['e/F01_phrases05_01.jpg', 'e'],\n ['e/F01_phrases05_02.jpg', 'e'],\n ['e/F01_phrases05_03.jpg', 'e'],\n ['e/F01_phrases05_04.jpg', 'e'],\n ['e/F01_phrases05_05.jpg', 'e'],\n ['e/F01_phrases05_06.jpg', 'e'],\n ['e/F01_phrases05_07.jpg', 'e'],\n ['e/F01_phrases05_08.jpg', 'e'],\n ['e/F01_phrases05_09.jpg', 'e'],\n ['e/F01_phrases05_10.jpg', 'e'],\n ['e/F02_phrases05_01.jpg', 'e'],\n ['e/F02_phrases05_02.jpg', 'e'],\n ['e/F02_phrases05_03.jpg', 'e'],\n ['e/F02_phrases05_04.jpg', 'e'],\n ['e/F04_phrases05_05.jpg', 'e'],\n ['e/F04_phrases05_06.jpg', 'e'],\n ['e/F04_phrases05_10.jpg', 'e'],\n ['e/F05_phrases05_01.jpg', 'e'],\n ['e/F05_phrases05_02.jpg', 'e'],\n ['e/F05_phrases05_03.jpg', 'e'],\n ['e/F05_phrases05_04.jpg', 'e'],\n ['e/F05_phrases05_05.jpg', 'e'],\n ['e/F05_phrases05_06.jpg', 'e'],\n ['e/F05_phrases05_07.jpg', 'e'],\n ['e/F05_phrases05_08.jpg', 'e'],\n ['e/F06_phrases05_06.jpg', 'e'],\n ['e/F06_phrases05_07.jpg', 'e'],\n ['e/F06_phrases05_08.jpg', 'e'],\n ['e/F06_phrases05_09.jpg', 'e'],\n ['e/F06_phrases05_10.jpg', 'e'],\n ['e/F07_phrases05_01.jpg', 'e'],\n ['e/F07_phrases05_02.jpg', 'e'],\n ['e/F07_phrases05_03.jpg', 'e'],\n ['e/F07_phrases05_04.jpg', 'e'],\n ['e/F07_phrases05_05.jpg', 'e'],\n ['e/F07_phrases05_06.jpg', 'e'],\n ['e/F07_phrases05_07.jpg', 'e'],\n ['e/F07_phrases05_08.jpg', 'e'],\n ['e/F07_phrases05_09.jpg', 'e'],\n ['e/F07_phrases05_10.jpg', 'e'],\n ['e/F08_phrases05_01.jpg', 'e'],\n ['e/F08_phrases05_02.jpg', 'e'],\n ['e/F08_phrases05_03.jpg', 'e'],\n ['e/F08_phrases05_04.jpg', 'e'],\n ['e/F08_phrases05_05.jpg', 'e'],\n ['e/F08_phrases05_06.jpg', 'e'],\n ['e/F08_phrases05_07.jpg', 'e'],\n ['e/F08_phrases05_08.jpg', 'e'],\n ['e/F08_phrases05_09.jpg', 'e'],\n ['e/F08_phrases05_10.jpg', 'e'],\n ['e/F09_phrases05_01.jpg', 'e'],\n ['e/F09_phrases05_02.jpg', 'e'],\n ['e/F09_phrases05_03.jpg', 'e'],\n ['e/F09_phrases05_04.jpg', 'e'],\n ['e/F09_phrases05_05.jpg', 'e'],\n ['e/F09_phrases05_06.jpg', 'e'],\n ['e/F09_phrases05_07.jpg', 'e'],\n ['e/F09_phrases05_08.jpg', 'e'],\n ['e/F09_phrases05_09.jpg', 'e'],\n ['e/F09_phrases05_10.jpg', 'e'],\n ['e/F10_phrases05_01.jpg', 'e'],\n ['e/F10_phrases05_02.jpg', 'e'],\n ['e/F10_phrases05_03.jpg', 'e'],\n ['e/F10_phrases05_04.jpg', 'e'],\n ['e/F10_phrases05_05.jpg', 'e'],\n ['e/F10_phrases05_06.jpg', 'e'],\n ['e/F10_phrases05_07.jpg', 'e'],\n ['e/F10_phrases05_08.jpg', 'e'],\n ['e/F10_phrases05_09.jpg', 'e'],\n ['e/F10_phrases05_10.jpg', 'e'],\n ['e/F11_phrases05_01.jpg', 'e'],\n ['e/F11_phrases05_02.jpg', 'e'],\n ['e/F11_phrases05_03.jpg', 'e'],\n ['e/F11_phrases05_04.jpg', 'e'],\n ['e/F11_phrases05_05.jpg', 'e'],\n ['e/F11_phrases05_06.jpg', 'e'],\n ['e/F11_phrases05_07.jpg', 'e'],\n ['e/F11_phrases05_08.jpg', 'e'],\n ['e/F11_phrases05_09.jpg', 'e'],\n ['e/F11_phrases05_10.jpg', 'e'],\n ['e/M01_phrases05_01.jpg', 'e'],\n ['e/M01_phrases05_02.jpg', 'e'],\n ['e/M01_phrases05_03.jpg', 'e'],\n ['e/M01_phrases05_04.jpg', 'e'],\n ['e/M01_phrases05_05.jpg', 'e'],\n ['e/M01_phrases05_06.jpg', 'e'],\n ['e/M01_phrases05_07.jpg', 'e'],\n ['e/M01_phrases05_08.jpg', 'e'],\n ['e/M01_phrases05_09.jpg', 'e'],\n ['e/M01_phrases05_10.jpg', 'e'],\n ['e/M02_phrases05_01.jpg', 'e'],\n ['e/M02_phrases05_02.jpg', 'e'],\n ['e/M02_phrases05_03.jpg', 'e'],\n ['e/M02_phrases05_04.jpg', 'e'],\n ['e/M02_phrases05_05.jpg', 'e'],\n ['e/M02_phrases05_06.jpg', 'e'],\n ['e/M02_phrases05_07.jpg', 'e'],\n ['e/M02_phrases05_08.jpg', 'e'],\n ['e/M02_phrases05_09.jpg', 'e'],\n ['e/M02_phrases05_10.jpg', 'e'],\n ['e/M04_phrases05_01.jpg', 'e'],\n ['e/M04_phrases05_02.jpg', 'e'],\n ['e/M04_phrases05_03.jpg', 'e'],\n ['e/M04_phrases05_04.jpg', 'e'],\n ['e/M04_phrases05_05.jpg', 'e'],\n ['e/M04_phrases05_06.jpg', 'e'],\n ['e/M04_phrases05_07.jpg', 'e'],\n ['e/M04_phrases05_08.jpg', 'e'],\n ['e/M04_phrases05_09.jpg', 'e'],\n ['e/M04_phrases05_10.jpg', 'e'],\n ['e/M07_phrases05_01.jpg', 'e'],\n ['e/M07_phrases05_02.jpg', 'e'],\n ['e/M07_phrases05_03.jpg', 'e'],\n ['e/M07_phrases05_04.jpg', 'e'],\n ['e/M07_phrases05_05.jpg', 'e'],\n ['e/M07_phrases05_06.jpg', 'e'],\n ['e/M07_phrases05_07.jpg', 'e'],\n ['e/M07_phrases05_08.jpg', 'e'],\n ['e/M07_phrases05_09.jpg', 'e'],\n ['e/M07_phrases05_10.jpg', 'e'],\n ['e/M08_phrases05_01.jpg', 'e'],\n ['e/M08_phrases05_02.jpg', 'e'],\n ['e/M08_phrases05_03.jpg', 'e'],\n ['e/M08_phrases05_04.jpg', 'e'],\n ['e/M08_phrases05_05.jpg', 'e'],\n ['e/M08_phrases05_06.jpg', 'e'],\n ['e/M08_phrases05_07.jpg', 'e'],\n ['e/M08_phrases05_08.jpg', 'e'],\n ['e/M08_phrases05_09.jpg', 'e'],\n ['e/M08_phrases05_10.jpg', 'e'],\n ['f/F02_phrases06_01.jpg', 'f'],\n ['f/F02_phrases06_02.jpg', 'f'],\n ['f/F02_phrases06_03.jpg', 'f'],\n ['f/F02_phrases06_04.jpg', 'f'],\n ['f/F02_phrases06_05.jpg', 'f'],\n ['f/F02_phrases06_06.jpg', 'f'],\n ['f/F02_phrases06_07.jpg', 'f'],\n ['f/F02_phrases06_08.jpg', 'f'],\n ['f/F02_phrases06_09.jpg', 'f'],\n ['f/F02_phrases06_10.jpg', 'f'],\n ['f/F04_phrases06_01.jpg', 'f'],\n ['f/F04_phrases06_02.jpg', 'f'],\n ['f/F04_phrases06_03.jpg', 'f'],\n ['f/F04_phrases06_04.jpg', 'f'],\n ['f/F04_phrases06_05.jpg', 'f'],\n ['f/F04_phrases06_06.jpg', 'f'],\n ['f/F05_phrases06_01.jpg', 'f'],\n ['f/F05_phrases06_02.jpg', 'f'],\n ['f/F05_phrases06_03.jpg', 'f'],\n ['f/F05_phrases06_04.jpg', 'f'],\n ['f/F05_phrases06_05.jpg', 'f'],\n ['f/F05_phrases06_06.jpg', 'f'],\n ['f/F05_phrases06_07.jpg', 'f'],\n ['f/F05_phrases06_08.jpg', 'f'],\n ['f/F05_phrases06_09.jpg', 'f'],\n ['f/F05_phrases06_10.jpg', 'f'],\n ['f/F06_phrases06_01.jpg', 'f'],\n ['f/F06_phrases06_02.jpg', 'f'],\n ['f/F06_phrases06_03.jpg', 'f'],\n ['f/F06_phrases06_07.jpg', 'f'],\n ['f/F06_phrases06_08.jpg', 'f'],\n ['f/F06_phrases06_09.jpg', 'f'],\n ['f/F06_phrases06_10.jpg', 'f'],\n ['f/F07_phrases06_01.jpg', 'f'],\n ['f/F07_phrases06_02.jpg', 'f'],\n ['f/F07_phrases06_03.jpg', 'f'],\n ['f/F07_phrases06_04.jpg', 'f'],\n ['f/F07_phrases06_05.jpg', 'f'],\n ['f/F07_phrases06_06.jpg', 'f'],\n ['f/F07_phrases06_07.jpg', 'f'],\n ['f/F07_phrases06_08.jpg', 'f'],\n ['f/F07_phrases06_09.jpg', 'f'],\n ['f/F07_phrases06_10.jpg', 'f'],\n ['f/F08_phrases06_04.jpg', 'f'],\n ['f/F08_phrases06_05.jpg', 'f'],\n ['f/F08_phrases06_06.jpg', 'f'],\n ['f/F08_phrases06_07.jpg', 'f'],\n ['f/F08_phrases06_08.jpg', 'f'],\n ['f/F08_phrases06_09.jpg', 'f'],\n ['f/F08_phrases06_10.jpg', 'f'],\n ['f/F09_phrases06_01.jpg', 'f'],\n ['f/F09_phrases06_02.jpg', 'f'],\n ['f/F09_phrases06_03.jpg', 'f'],\n ['f/F09_phrases06_04.jpg', 'f'],\n ['f/F09_phrases06_05.jpg', 'f'],\n ['f/F09_phrases06_06.jpg', 'f'],\n ['f/F09_phrases06_07.jpg', 'f'],\n ['f/F09_phrases06_08.jpg', 'f'],\n ['f/F09_phrases06_09.jpg', 'f'],\n ['f/F09_phrases06_10.jpg', 'f'],\n ['f/F10_phrases06_01.jpg', 'f'],\n ['f/F10_phrases06_02.jpg', 'f'],\n ['f/F10_phrases06_03.jpg', 'f'],\n ['f/F10_phrases06_04.jpg', 'f'],\n ['f/F10_phrases06_05.jpg', 'f'],\n ['f/F10_phrases06_06.jpg', 'f'],\n ['f/F10_phrases06_07.jpg', 'f'],\n ['f/F10_phrases06_08.jpg', 'f'],\n ['f/F10_phrases06_09.jpg', 'f'],\n ['f/F10_phrases06_10.jpg', 'f'],\n ['f/F11_phrases06_01.jpg', 'f'],\n ['f/F11_phrases06_02.jpg', 'f'],\n ['f/F11_phrases06_03.jpg', 'f'],\n ['f/F11_phrases06_04.jpg', 'f'],\n ['f/F11_phrases06_05.jpg', 'f'],\n ['f/F11_phrases06_06.jpg', 'f'],\n ['f/F11_phrases06_07.jpg', 'f'],\n ['f/F11_phrases06_08.jpg', 'f'],\n ['f/F11_phrases06_09.jpg', 'f'],\n ['f/F11_phrases06_10.jpg', 'f'],\n ['f/M01_phrases06_01.jpg', 'f'],\n ['f/M01_phrases06_02.jpg', 'f'],\n ['f/M01_phrases06_03.jpg', 'f'],\n ['f/M01_phrases06_04.jpg', 'f'],\n ['f/M01_phrases06_05.jpg', 'f'],\n ['f/M01_phrases06_06.jpg', 'f'],\n ['f/M01_phrases06_07.jpg', 'f'],\n ['f/M01_phrases06_08.jpg', 'f'],\n ['f/M01_phrases06_09.jpg', 'f'],\n ['f/M01_phrases06_10.jpg', 'f'],\n ['f/M02_phrases06_01.jpg', 'f'],\n ['f/M02_phrases06_02.jpg', 'f'],\n ['f/M02_phrases06_03.jpg', 'f'],\n ['f/M02_phrases06_04.jpg', 'f'],\n ['f/M02_phrases06_05.jpg', 'f'],\n ['f/M02_phrases06_06.jpg', 'f'],\n ['f/M02_phrases06_07.jpg', 'f'],\n ['f/M02_phrases06_08.jpg', 'f'],\n ['f/M02_phrases06_09.jpg', 'f'],\n ['f/M02_phrases06_10.jpg', 'f'],\n ['f/M04_phrases06_01.jpg', 'f'],\n ['f/M04_phrases06_02.jpg', 'f'],\n ['f/M04_phrases06_03.jpg', 'f'],\n ['f/M04_phrases06_04.jpg', 'f'],\n ['f/M04_phrases06_05.jpg', 'f'],\n ['f/M04_phrases06_06.jpg', 'f'],\n ['f/M04_phrases06_07.jpg', 'f'],\n ['f/M04_phrases06_08.jpg', 'f'],\n ['f/M04_phrases06_09.jpg', 'f'],\n ['f/M04_phrases06_10.jpg', 'f'],\n ['f/M07_phrases06_01.jpg', 'f'],\n ['f/M07_phrases06_02.jpg', 'f'],\n ['f/M07_phrases06_03.jpg', 'f'],\n ['f/M07_phrases06_04.jpg', 'f'],\n ['f/M07_phrases06_05.jpg', 'f'],\n ['f/M07_phrases06_06.jpg', 'f'],\n ['f/M07_phrases06_07.jpg', 'f'],\n ['f/M07_phrases06_08.jpg', 'f'],\n ['f/M07_phrases06_09.jpg', 'f'],\n ['f/M07_phrases06_10.jpg', 'f'],\n ['f/M08_phrases06_01.jpg', 'f'],\n ['f/M08_phrases06_02.jpg', 'f'],\n ['f/M08_phrases06_03.jpg', 'f'],\n ['f/M08_phrases06_04.jpg', 'f'],\n ['f/M08_phrases06_05.jpg', 'f'],\n ['f/M08_phrases06_06.jpg', 'f'],\n ['f/M08_phrases06_07.jpg', 'f'],\n ['f/M08_phrases06_08.jpg', 'f'],\n ['f/M08_phrases06_09.jpg', 'f'],\n ['f/M08_phrases06_10.jpg', 'f'],\n ['g/F01_phrases07_01.jpg', 'g'],\n ['g/F01_phrases07_02.jpg', 'g'],\n ['g/F01_phrases07_03.jpg', 'g'],\n ['g/F01_phrases07_04.jpg', 'g'],\n ['g/F01_phrases07_05.jpg', 'g'],\n ['g/F01_phrases07_06.jpg', 'g'],\n ['g/F01_phrases07_07.jpg', 'g'],\n ['g/F01_phrases07_08.jpg', 'g'],\n ['g/F01_phrases07_09.jpg', 'g'],\n ['g/F01_phrases07_10.jpg', 'g'],\n ['g/F02_phrases07_01.jpg', 'g'],\n ['g/F02_phrases07_02.jpg', 'g'],\n ['g/F02_phrases07_03.jpg', 'g'],\n ['g/F02_phrases07_04.jpg', 'g'],\n ['g/F02_phrases07_05.jpg', 'g'],\n ['g/F02_phrases07_06.jpg', 'g'],\n ['g/F02_phrases07_07.jpg', 'g'],\n ['g/F02_phrases07_08.jpg', 'g'],\n ['g/F02_phrases07_09.jpg', 'g'],\n ['g/F02_phrases07_10.jpg', 'g'],\n ['g/F04_phrases07_01.jpg', 'g'],\n ['g/F04_phrases07_02.jpg', 'g'],\n ['g/F04_phrases07_03.jpg', 'g'],\n ['g/F04_phrases07_04.jpg', 'g'],\n ['g/F04_phrases07_05.jpg', 'g'],\n ['g/F04_phrases07_06.jpg', 'g'],\n ['g/F04_phrases07_07.jpg', 'g'],\n ['g/F04_phrases07_08.jpg', 'g'],\n ['g/F04_phrases07_09.jpg', 'g'],\n ['g/F04_phrases07_10.jpg', 'g'],\n ['g/F05_phrases07_01.jpg', 'g'],\n ['g/F05_phrases07_02.jpg', 'g'],\n ['g/F05_phrases07_03.jpg', 'g'],\n ['g/F05_phrases07_04.jpg', 'g'],\n ['g/F05_phrases07_05.jpg', 'g'],\n ['g/F05_phrases07_06.jpg', 'g'],\n ['g/F05_phrases07_07.jpg', 'g'],\n ['g/F05_phrases07_08.jpg', 'g'],\n ['g/F05_phrases07_09.jpg', 'g'],\n ['g/F05_phrases07_10.jpg', 'g'],\n ['g/F06_phrases07_01.jpg', 'g'],\n ['g/F06_phrases07_02.jpg', 'g'],\n ['g/F06_phrases07_03.jpg', 'g'],\n ['g/F06_phrases07_04.jpg', 'g'],\n ['g/F06_phrases07_05.jpg', 'g'],\n ['g/F06_phrases07_06.jpg', 'g'],\n ['g/F06_phrases07_07.jpg', 'g'],\n ['g/F06_phrases07_08.jpg', 'g'],\n ['g/F06_phrases07_09.jpg', 'g'],\n ['g/F06_phrases07_10.jpg', 'g'],\n ['g/F07_phrases07_01.jpg', 'g'],\n ['g/F07_phrases07_02.jpg', 'g'],\n ['g/F07_phrases07_03.jpg', 'g'],\n ['g/F07_phrases07_04.jpg', 'g'],\n ['g/F07_phrases07_05.jpg', 'g'],\n ['g/F07_phrases07_06.jpg', 'g'],\n ['g/F07_phrases07_07.jpg', 'g'],\n ['g/F07_phrases07_08.jpg', 'g'],\n ['g/F07_phrases07_09.jpg', 'g'],\n ['g/F07_phrases07_10.jpg', 'g'],\n ['g/F08_phrases07_01.jpg', 'g'],\n ['g/F08_phrases07_02.jpg', 'g'],\n ['g/F08_phrases07_03.jpg', 'g'],\n ['g/F08_phrases07_04.jpg', 'g'],\n ['g/F08_phrases07_05.jpg', 'g'],\n ['g/F08_phrases07_06.jpg', 'g'],\n ['g/F08_phrases07_08.jpg', 'g'],\n ['g/F08_phrases07_09.jpg', 'g'],\n ['g/F08_phrases07_10.jpg', 'g'],\n ['g/F09_phrases07_01.jpg', 'g'],\n ['g/F09_phrases07_02.jpg', 'g'],\n ['g/F09_phrases07_03.jpg', 'g'],\n ['g/F09_phrases07_05.jpg', 'g'],\n ['g/F09_phrases07_06.jpg', 'g'],\n ['g/F09_phrases07_07.jpg', 'g'],\n ['g/F09_phrases07_08.jpg', 'g'],\n ['g/F09_phrases07_09.jpg', 'g'],\n ['g/F09_phrases07_10.jpg', 'g'],\n ['g/F10_phrases07_01.jpg', 'g'],\n ['g/F10_phrases07_02.jpg', 'g'],\n ['g/F10_phrases07_03.jpg', 'g'],\n ['g/F10_phrases07_04.jpg', 'g'],\n ['g/F10_phrases07_05.jpg', 'g'],\n ['g/F10_phrases07_06.jpg', 'g'],\n ['g/F10_phrases07_10.jpg', 'g'],\n ['g/F11_phrases07_01.jpg', 'g'],\n ['g/F11_phrases07_04.jpg', 'g'],\n ['g/F11_phrases07_05.jpg', 'g'],\n ['g/F11_phrases07_06.jpg', 'g'],\n ['g/F11_phrases07_07.jpg', 'g'],\n ['g/F11_phrases07_08.jpg', 'g'],\n ['g/F11_phrases07_09.jpg', 'g'],\n ['g/F11_phrases07_10.jpg', 'g'],\n ['g/M01_phrases07_02.jpg', 'g'],\n ['g/M01_phrases07_03.jpg', 'g'],\n ['g/M01_phrases07_04.jpg', 'g'],\n ['g/M01_phrases07_05.jpg', 'g'],\n ['g/M01_phrases07_08.jpg', 'g'],\n ['g/M01_phrases07_09.jpg', 'g'],\n ['g/M01_phrases07_10.jpg', 'g'],\n ['g/M04_phrases07_01.jpg', 'g'],\n ['g/M04_phrases07_02.jpg', 'g'],\n ['g/M04_phrases07_03.jpg', 'g'],\n ['g/M04_phrases07_04.jpg', 'g'],\n ['g/M04_phrases07_05.jpg', 'g'],\n ['g/M04_phrases07_06.jpg', 'g'],\n ['g/M04_phrases07_07.jpg', 'g'],\n ['g/M04_phrases07_08.jpg', 'g'],\n ['g/M04_phrases07_09.jpg', 'g'],\n ['g/M04_phrases07_10.jpg', 'g'],\n ['g/M07_phrases07_01.jpg', 'g'],\n ['g/M07_phrases07_02.jpg', 'g'],\n ['g/M07_phrases07_03.jpg', 'g'],\n ['g/M07_phrases07_04.jpg', 'g'],\n ['g/M07_phrases07_05.jpg', 'g'],\n ['g/M07_phrases07_06.jpg', 'g'],\n ['g/M07_phrases07_07.jpg', 'g'],\n ['g/M07_phrases07_08.jpg', 'g'],\n ['g/M07_phrases07_09.jpg', 'g'],\n ['g/M07_phrases07_10.jpg', 'g'],\n ['g/M08_phrases07_01.jpg', 'g'],\n ['g/M08_phrases07_02.jpg', 'g'],\n ['g/M08_phrases07_03.jpg', 'g'],\n ['g/M08_phrases07_04.jpg', 'g'],\n ['g/M08_phrases07_05.jpg', 'g'],\n ['g/M08_phrases07_06.jpg', 'g'],\n ['g/M08_phrases07_07.jpg', 'g'],\n ['g/M08_phrases07_08.jpg', 'g'],\n ['g/M08_phrases07_09.jpg', 'g'],\n ['g/M08_phrases07_10.jpg', 'g'],\n ['h/F01_phrases08_01.jpg', 'h'],\n ['h/F01_phrases08_02.jpg', 'h'],\n ['h/F01_phrases08_03.jpg', 'h'],\n ['h/F01_phrases08_04.jpg', 'h'],\n ['h/F01_phrases08_05.jpg', 'h'],\n ['h/F01_phrases08_06.jpg', 'h'],\n ['h/F01_phrases08_07.jpg', 'h'],\n ['h/F01_phrases08_08.jpg', 'h'],\n ['h/F01_phrases08_09.jpg', 'h'],\n ['h/F02_phrases08_02.jpg', 'h'],\n ['h/F02_phrases08_03.jpg', 'h'],\n ['h/F02_phrases08_04.jpg', 'h'],\n ['h/F02_phrases08_05.jpg', 'h'],\n ['h/F02_phrases08_06.jpg', 'h'],\n ['h/F02_phrases08_07.jpg', 'h'],\n ['h/F02_phrases08_08.jpg', 'h'],\n ['h/F02_phrases08_09.jpg', 'h'],\n ['h/F02_phrases08_10.jpg', 'h'],\n ['h/F04_phrases08_01.jpg', 'h'],\n ['h/F04_phrases08_02.jpg', 'h'],\n ['h/F04_phrases08_03.jpg', 'h'],\n ['h/F04_phrases08_04.jpg', 'h'],\n ['h/F04_phrases08_05.jpg', 'h'],\n ['h/F04_phrases08_06.jpg', 'h'],\n ['h/F04_phrases08_07.jpg', 'h'],\n ['h/F04_phrases08_08.jpg', 'h'],\n ['h/F04_phrases08_09.jpg', 'h'],\n ['h/F04_phrases08_10.jpg', 'h'],\n ['h/F06_phrases08_01.jpg', 'h'],\n ['h/F06_phrases08_02.jpg', 'h'],\n ['h/F06_phrases08_06.jpg', 'h'],\n ['h/F06_phrases08_07.jpg', 'h'],\n ['h/F06_phrases08_08.jpg', 'h'],\n ['h/F06_phrases08_09.jpg', 'h'],\n ['h/F06_phrases08_10.jpg', 'h'],\n ['h/F07_phrases08_01.jpg', 'h'],\n ['h/F07_phrases08_02.jpg', 'h'],\n ['h/F07_phrases08_03.jpg', 'h'],\n ['h/F07_phrases08_04.jpg', 'h'],\n ['h/F07_phrases08_05.jpg', 'h'],\n ['h/F08_phrases08_01.jpg', 'h'],\n ['h/F08_phrases08_02.jpg', 'h'],\n ['h/F08_phrases08_03.jpg', 'h'],\n ['h/F08_phrases08_04.jpg', 'h'],\n ['h/F08_phrases08_05.jpg', 'h'],\n ['h/F08_phrases08_06.jpg', 'h'],\n ['h/F08_phrases08_07.jpg', 'h'],\n ['h/F08_phrases08_08.jpg', 'h'],\n ['h/F08_phrases08_09.jpg', 'h'],\n ['h/F08_phrases08_10.jpg', 'h'],\n ['h/F09_phrases08_01.jpg', 'h'],\n ['h/F09_phrases08_02.jpg', 'h'],\n ['h/F09_phrases08_03.jpg', 'h'],\n ['h/F09_phrases08_04.jpg', 'h'],\n ['h/F09_phrases08_05.jpg', 'h'],\n ['h/F09_phrases08_06.jpg', 'h'],\n ['h/F09_phrases08_07.jpg', 'h'],\n ['h/F09_phrases08_08.jpg', 'h'],\n ['h/F09_phrases08_09.jpg', 'h'],\n ['h/F09_phrases08_10.jpg', 'h'],\n ['h/F10_phrases08_01.jpg', 'h'],\n ['h/F10_phrases08_02.jpg', 'h'],\n ['h/F10_phrases08_03.jpg', 'h'],\n ['h/F10_phrases08_04.jpg', 'h'],\n ['h/F10_phrases08_05.jpg', 'h'],\n ['h/F10_phrases08_06.jpg', 'h'],\n ['h/F10_phrases08_07.jpg', 'h'],\n ['h/F10_phrases08_08.jpg', 'h'],\n ['h/F10_phrases08_09.jpg', 'h'],\n ['h/F10_phrases08_10.jpg', 'h'],\n ['h/F11_phrases08_01.jpg', 'h'],\n ['h/F11_phrases08_02.jpg', 'h'],\n ['h/F11_phrases08_03.jpg', 'h'],\n ['h/F11_phrases08_04.jpg', 'h'],\n ['h/F11_phrases08_05.jpg', 'h'],\n ['h/F11_phrases08_06.jpg', 'h'],\n ['h/F11_phrases08_07.jpg', 'h'],\n ['h/F11_phrases08_08.jpg', 'h'],\n ['h/F11_phrases08_09.jpg', 'h'],\n ['h/F11_phrases08_10.jpg', 'h'],\n ['h/M01_phrases08_01.jpg', 'h'],\n ['h/M01_phrases08_02.jpg', 'h'],\n ['h/M01_phrases08_03.jpg', 'h'],\n ['h/M01_phrases08_04.jpg', 'h'],\n ['h/M01_phrases08_05.jpg', 'h'],\n ['h/M01_phrases08_06.jpg', 'h'],\n ['h/M01_phrases08_07.jpg', 'h'],\n ['h/M01_phrases08_08.jpg', 'h'],\n ['h/M01_phrases08_09.jpg', 'h'],\n ['h/M01_phrases08_10.jpg', 'h'],\n ['h/M02_phrases08_01.jpg', 'h'],\n ['h/M02_phrases08_02.jpg', 'h'],\n ['h/M02_phrases08_03.jpg', 'h'],\n ['h/M02_phrases08_04.jpg', 'h'],\n ['h/M02_phrases08_05.jpg', 'h'],\n ['h/M02_phrases08_06.jpg', 'h'],\n ['h/M02_phrases08_07.jpg', 'h'],\n ['h/M02_phrases08_08.jpg', 'h'],\n ['h/M02_phrases08_09.jpg', 'h'],\n ['h/M02_phrases08_10.jpg', 'h'],\n ['h/M04_phrases08_01.jpg', 'h'],\n ['h/M04_phrases08_02.jpg', 'h'],\n ['h/M04_phrases08_03.jpg', 'h'],\n ['h/M04_phrases08_04.jpg', 'h'],\n ['h/M04_phrases08_05.jpg', 'h'],\n ...]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e5c725d-fc2f-4eb5-9882-1ae79544ec2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\Daniele\\\\PycharmProjects\\\\LipNetProve\\\\Dataset\\\\Train'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fa036c7-0f3e-4efd-ab4f-abada0d1b809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "os.chdir('../../codes')\n",
    "header = ['filename', 'label']\n",
    "\n",
    "with open('training_labels.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # write the header\n",
    "    writer.writerow(header)\n",
    "\n",
    "    # write multiple rows\n",
    "    writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58c1efce-1e0b-43fc-a54f-da4d1de51589",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('training_labels.csv')\n",
    "Y = train_data[['label']]\n",
    "\n",
    "kf = KFold(n_splits = 5)\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 5, random_state = 7, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e5eb1be-ef1b-4513-907e-9696ee6b7fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "idg = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "469e5e7c-14dc-4966-a69d-5f6dc75ec425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(k):\n",
    "    return 'model_'+str(k)+'.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dabce5b3-e238-4bb1-865a-0961f7288a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_model():\n",
    "    import os\n",
    "    import numpy as np\n",
    "    from keras.models import Sequential # To initialise the nn as a sequence of layers\n",
    "    from keras.layers import Convolution2D # To make the convolution layer for 2D images\n",
    "    from keras.layers import MaxPooling2D #\n",
    "    from keras.layers import Flatten\n",
    "    from keras.layers import Dense\n",
    "    from keras.layers import Dropout\n",
    "    from keras.callbacks import CSVLogger\n",
    "    from tensorflow.keras.optimizers import RMSprop\n",
    "    from keras.layers import BatchNormalization\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    from keras.models import load_model\n",
    "    from keras.callbacks import ModelCheckpoint\n",
    "    from keras.layers import Activation\n",
    "    from keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "    \n",
    "    csv = CSVLogger(\"2_adam.log\")\n",
    "    #filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "    #checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    # Initialising the CNN\n",
    "    classifier = Sequential()\n",
    "\n",
    "    # Step 1 - Convolution\n",
    "    classifier.add(Convolution2D(32, (2, 2), input_shape=(224, 224, 1), activation='relu', strides=2, name='convo1'))\n",
    "    classifier.add(Convolution2D(64, (3, 3), activation='relu', name='convo2'))\n",
    "    # Step 1 - Pooling\n",
    "    classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Step 2 - Convolution\n",
    "    classifier.add(Convolution2D(64, (3, 3), activation='relu', name='convo3'))\n",
    "    # Step 2 - Pooling\n",
    "    classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Step 3 - Convolution\n",
    "    classifier.add(Convolution2D(64, (3, 3), activation='relu', name='convo4'))\n",
    "    # Step 3 - Pooling\n",
    "    classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #Step 4 - Flattening\n",
    "\n",
    "    classifier.add(Flatten())\n",
    "\n",
    "    classifier.add(BatchNormalization())\n",
    "    classifier.add(Dropout((0.5)))\n",
    "    classifier.add(Dense(1024, activation='relu'))\n",
    "\n",
    "    '''classifier.add(BatchNormalization())\n",
    "    classifier.add(Dropout((0.5)))\n",
    "    classifier.add(Dense(512, activation = 'relu'))\n",
    "    '''\n",
    "\n",
    "    classifier.add(BatchNormalization())\n",
    "    classifier.add(Dropout((0.4)))\n",
    "    classifier.add(Dense(20, activation='softmax'))\n",
    "\n",
    "    return classifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "141b06b1-a1d3-4715-b21d-2382e18fb087",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/keras_preprocessing/image/dataframe_iterator.py:279: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2080 validated image filenames belonging to 20 classes.\n",
      "Found 520 validated image filenames belonging to 20 classes.\n",
      "Epoch 1/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 3.3261 - accuracy: 0.1712\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.11731, saving model to saved_models/model_1.h5\n",
      "65/65 [==============================] - 54s 816ms/step - loss: 3.3261 - accuracy: 0.1712 - val_loss: 2.9208 - val_accuracy: 0.1173\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 2.0510 - accuracy: 0.4202\n",
      "Epoch 00002: val_accuracy did not improve from 0.11731\n",
      "65/65 [==============================] - 54s 824ms/step - loss: 2.0510 - accuracy: 0.4202 - val_loss: 2.9475 - val_accuracy: 0.1173\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 1.4017 - accuracy: 0.5798\n",
      "Epoch 00003: val_accuracy improved from 0.11731 to 0.19038, saving model to saved_models/model_1.h5\n",
      "65/65 [==============================] - 53s 815ms/step - loss: 1.4017 - accuracy: 0.5798 - val_loss: 2.7735 - val_accuracy: 0.1904\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.9604 - accuracy: 0.6918\n",
      "Epoch 00004: val_accuracy did not improve from 0.19038\n",
      "65/65 [==============================] - 58s 897ms/step - loss: 0.9604 - accuracy: 0.6918 - val_loss: 2.8409 - val_accuracy: 0.1731\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.7357 - accuracy: 0.7639\n",
      "Epoch 00005: val_accuracy improved from 0.19038 to 0.35000, saving model to saved_models/model_1.h5\n",
      "65/65 [==============================] - 52s 792ms/step - loss: 0.7357 - accuracy: 0.7639 - val_loss: 2.3990 - val_accuracy: 0.3500\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.5123 - accuracy: 0.8293\n",
      "Epoch 00006: val_accuracy improved from 0.35000 to 0.36154, saving model to saved_models/model_1.h5\n",
      "65/65 [==============================] - 56s 858ms/step - loss: 0.5123 - accuracy: 0.8293 - val_loss: 2.1521 - val_accuracy: 0.3615\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.3589 - accuracy: 0.8798\n",
      "Epoch 00007: val_accuracy improved from 0.36154 to 0.41346, saving model to saved_models/model_1.h5\n",
      "65/65 [==============================] - 52s 801ms/step - loss: 0.3589 - accuracy: 0.8798 - val_loss: 1.7584 - val_accuracy: 0.4135\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2869 - accuracy: 0.9077\n",
      "Epoch 00008: val_accuracy improved from 0.41346 to 0.49231, saving model to saved_models/model_1.h5\n",
      "65/65 [==============================] - 51s 793ms/step - loss: 0.2869 - accuracy: 0.9077 - val_loss: 1.6025 - val_accuracy: 0.4923\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2167 - accuracy: 0.9231\n",
      "Epoch 00009: val_accuracy improved from 0.49231 to 0.64615, saving model to saved_models/model_1.h5\n",
      "65/65 [==============================] - 58s 896ms/step - loss: 0.2167 - accuracy: 0.9231 - val_loss: 1.0657 - val_accuracy: 0.6462\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1838 - accuracy: 0.9389\n",
      "Epoch 00010: val_accuracy did not improve from 0.64615\n",
      "65/65 [==============================] - 59s 900ms/step - loss: 0.1838 - accuracy: 0.9389 - val_loss: 1.8837 - val_accuracy: 0.4904\n",
      "Sto salvando\n",
      "17/17 [==============================] - 4s 206ms/step - loss: 1.0657 - accuracy: 0.6462\n",
      "Found 2079 validated image filenames belonging to 20 classes.\n",
      "Found 521 validated image filenames belonging to 20 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/keras_preprocessing/image/dataframe_iterator.py:279: UserWarning: Found 2 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 3.3202 - accuracy: 0.1592\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.06718, saving model to saved_models/model_2.h5\n",
      "65/65 [==============================] - 62s 934ms/step - loss: 3.3202 - accuracy: 0.1592 - val_loss: 2.9400 - val_accuracy: 0.0672\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 2.2890 - accuracy: 0.3646\n",
      "Epoch 00002: val_accuracy did not improve from 0.06718\n",
      "65/65 [==============================] - 64s 985ms/step - loss: 2.2890 - accuracy: 0.3646 - val_loss: 2.9709 - val_accuracy: 0.0595\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 1.6130 - accuracy: 0.5402\n",
      "Epoch 00003: val_accuracy improved from 0.06718 to 0.12284, saving model to saved_models/model_2.h5\n",
      "65/65 [==============================] - 56s 859ms/step - loss: 1.6130 - accuracy: 0.5402 - val_loss: 2.7501 - val_accuracy: 0.1228\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 1.3183 - accuracy: 0.6094\n",
      "Epoch 00004: val_accuracy improved from 0.12284 to 0.20537, saving model to saved_models/model_2.h5\n",
      "65/65 [==============================] - 54s 838ms/step - loss: 1.3183 - accuracy: 0.6094 - val_loss: 2.5692 - val_accuracy: 0.2054\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.9593 - accuracy: 0.6883\n",
      "Epoch 00005: val_accuracy improved from 0.20537 to 0.24568, saving model to saved_models/model_2.h5\n",
      "65/65 [==============================] - 47s 721ms/step - loss: 0.9593 - accuracy: 0.6883 - val_loss: 2.3645 - val_accuracy: 0.2457\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.6891 - accuracy: 0.7783\n",
      "Epoch 00006: val_accuracy improved from 0.24568 to 0.25528, saving model to saved_models/model_2.h5\n",
      "65/65 [==============================] - 47s 718ms/step - loss: 0.6891 - accuracy: 0.7783 - val_loss: 2.1282 - val_accuracy: 0.2553\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.5381 - accuracy: 0.8206\n",
      "Epoch 00007: val_accuracy improved from 0.25528 to 0.44338, saving model to saved_models/model_2.h5\n",
      "65/65 [==============================] - 46s 709ms/step - loss: 0.5381 - accuracy: 0.8206 - val_loss: 1.7270 - val_accuracy: 0.4434\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.4033 - accuracy: 0.8711\n",
      "Epoch 00008: val_accuracy did not improve from 0.44338\n",
      "65/65 [==============================] - 47s 721ms/step - loss: 0.4033 - accuracy: 0.8711 - val_loss: 1.9942 - val_accuracy: 0.4261\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.3319 - accuracy: 0.8923\n",
      "Epoch 00009: val_accuracy improved from 0.44338 to 0.58157, saving model to saved_models/model_2.h5\n",
      "65/65 [==============================] - 47s 718ms/step - loss: 0.3319 - accuracy: 0.8923 - val_loss: 1.3222 - val_accuracy: 0.5816\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.3234 - accuracy: 0.8971\n",
      "Epoch 00010: val_accuracy improved from 0.58157 to 0.64107, saving model to saved_models/model_2.h5\n",
      "65/65 [==============================] - 46s 707ms/step - loss: 0.3234 - accuracy: 0.8971 - val_loss: 1.1353 - val_accuracy: 0.6411\n",
      "Sto salvando\n",
      "17/17 [==============================] - 3s 156ms/step - loss: 1.1353 - accuracy: 0.6411\n",
      "Found 2080 validated image filenames belonging to 20 classes.\n",
      "Found 520 validated image filenames belonging to 20 classes.\n",
      "Epoch 1/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 3.4327 - accuracy: 0.1447\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.07692, saving model to saved_models/model_3.h5\n",
      "65/65 [==============================] - 47s 719ms/step - loss: 3.4327 - accuracy: 0.1447 - val_loss: 2.9638 - val_accuracy: 0.0769\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 2.2430 - accuracy: 0.3721\n",
      "Epoch 00002: val_accuracy improved from 0.07692 to 0.08077, saving model to saved_models/model_3.h5\n",
      "65/65 [==============================] - 46s 712ms/step - loss: 2.2430 - accuracy: 0.3721 - val_loss: 2.9538 - val_accuracy: 0.0808\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 1.4123 - accuracy: 0.5745\n",
      "Epoch 00003: val_accuracy improved from 0.08077 to 0.15577, saving model to saved_models/model_3.h5\n",
      "65/65 [==============================] - 46s 710ms/step - loss: 1.4123 - accuracy: 0.5745 - val_loss: 2.8301 - val_accuracy: 0.1558\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.9547 - accuracy: 0.6861\n",
      "Epoch 00004: val_accuracy improved from 0.15577 to 0.24038, saving model to saved_models/model_3.h5\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 0.9547 - accuracy: 0.6861 - val_loss: 2.5662 - val_accuracy: 0.2404\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.6382 - accuracy: 0.7856\n",
      "Epoch 00005: val_accuracy did not improve from 0.24038\n",
      "65/65 [==============================] - 46s 707ms/step - loss: 0.6382 - accuracy: 0.7856 - val_loss: 2.5416 - val_accuracy: 0.2000\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.4354 - accuracy: 0.8625\n",
      "Epoch 00006: val_accuracy improved from 0.24038 to 0.37692, saving model to saved_models/model_3.h5\n",
      "65/65 [==============================] - 46s 704ms/step - loss: 0.4354 - accuracy: 0.8625 - val_loss: 2.0870 - val_accuracy: 0.3769\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.3272 - accuracy: 0.8923\n",
      "Epoch 00007: val_accuracy improved from 0.37692 to 0.45385, saving model to saved_models/model_3.h5\n",
      "65/65 [==============================] - 46s 706ms/step - loss: 0.3272 - accuracy: 0.8923 - val_loss: 1.7721 - val_accuracy: 0.4538\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2720 - accuracy: 0.9115\n",
      "Epoch 00008: val_accuracy did not improve from 0.45385\n",
      "65/65 [==============================] - 46s 706ms/step - loss: 0.2720 - accuracy: 0.9115 - val_loss: 2.0096 - val_accuracy: 0.3712\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1969 - accuracy: 0.9337\n",
      "Epoch 00009: val_accuracy did not improve from 0.45385\n",
      "65/65 [==============================] - 46s 701ms/step - loss: 0.1969 - accuracy: 0.9337 - val_loss: 1.8605 - val_accuracy: 0.4212\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1851 - accuracy: 0.9409\n",
      "Epoch 00010: val_accuracy improved from 0.45385 to 0.66923, saving model to saved_models/model_3.h5\n",
      "65/65 [==============================] - 46s 706ms/step - loss: 0.1851 - accuracy: 0.9409 - val_loss: 1.2067 - val_accuracy: 0.6692\n",
      "Sto salvando\n",
      "17/17 [==============================] - 3s 155ms/step - loss: 1.2067 - accuracy: 0.6692\n",
      "Found 2081 validated image filenames belonging to 20 classes.\n",
      "Found 519 validated image filenames belonging to 20 classes.\n",
      "Epoch 1/10\n",
      "66/66 [==============================] - ETA: 0s - loss: 3.3403 - accuracy: 0.1639\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.12331, saving model to saved_models/model_4.h5\n",
      "66/66 [==============================] - 47s 702ms/step - loss: 3.3403 - accuracy: 0.1639 - val_loss: 2.9480 - val_accuracy: 0.1233\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - ETA: 0s - loss: 2.1738 - accuracy: 0.4080\n",
      "Epoch 00002: val_accuracy did not improve from 0.12331\n",
      "66/66 [==============================] - 46s 695ms/step - loss: 2.1738 - accuracy: 0.4080 - val_loss: 2.8294 - val_accuracy: 0.1060\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - ETA: 0s - loss: 1.4962 - accuracy: 0.5420\n",
      "Epoch 00003: val_accuracy improved from 0.12331 to 0.18497, saving model to saved_models/model_4.h5\n",
      "66/66 [==============================] - 46s 696ms/step - loss: 1.4962 - accuracy: 0.5420 - val_loss: 3.0061 - val_accuracy: 0.1850\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - ETA: 0s - loss: 1.0213 - accuracy: 0.6704\n",
      "Epoch 00004: val_accuracy improved from 0.18497 to 0.25048, saving model to saved_models/model_4.h5\n",
      "66/66 [==============================] - 46s 697ms/step - loss: 1.0213 - accuracy: 0.6704 - val_loss: 2.6548 - val_accuracy: 0.2505\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.7628 - accuracy: 0.7516\n",
      "Epoch 00005: val_accuracy did not improve from 0.25048\n",
      "66/66 [==============================] - 46s 696ms/step - loss: 0.7628 - accuracy: 0.7516 - val_loss: 2.5609 - val_accuracy: 0.1657\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.5590 - accuracy: 0.8160\n",
      "Epoch 00006: val_accuracy improved from 0.25048 to 0.43931, saving model to saved_models/model_4.h5\n",
      "66/66 [==============================] - 46s 698ms/step - loss: 0.5590 - accuracy: 0.8160 - val_loss: 2.2298 - val_accuracy: 0.4393\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.5067 - accuracy: 0.8328\n",
      "Epoch 00007: val_accuracy improved from 0.43931 to 0.45857, saving model to saved_models/model_4.h5\n",
      "66/66 [==============================] - 46s 697ms/step - loss: 0.5067 - accuracy: 0.8328 - val_loss: 1.8766 - val_accuracy: 0.4586\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.3517 - accuracy: 0.8832\n",
      "Epoch 00008: val_accuracy improved from 0.45857 to 0.49518, saving model to saved_models/model_4.h5\n",
      "66/66 [==============================] - 46s 696ms/step - loss: 0.3517 - accuracy: 0.8832 - val_loss: 1.6590 - val_accuracy: 0.4952\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.2826 - accuracy: 0.9135\n",
      "Epoch 00009: val_accuracy improved from 0.49518 to 0.57996, saving model to saved_models/model_4.h5\n",
      "66/66 [==============================] - 46s 703ms/step - loss: 0.2826 - accuracy: 0.9135 - val_loss: 1.4198 - val_accuracy: 0.5800\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.2391 - accuracy: 0.9202\n",
      "Epoch 00010: val_accuracy did not improve from 0.57996\n",
      "66/66 [==============================] - 46s 693ms/step - loss: 0.2391 - accuracy: 0.9202 - val_loss: 3.3011 - val_accuracy: 0.3892\n",
      "Sto salvando\n",
      "17/17 [==============================] - 3s 162ms/step - loss: 1.4198 - accuracy: 0.5800\n",
      "Found 2080 validated image filenames belonging to 20 classes.\n",
      "Found 520 validated image filenames belonging to 20 classes.\n",
      "Epoch 1/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 3.3111 - accuracy: 0.1745\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.11346, saving model to saved_models/model_5.h5\n",
      "65/65 [==============================] - 49s 737ms/step - loss: 3.3111 - accuracy: 0.1745 - val_loss: 2.9038 - val_accuracy: 0.1135\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 2.0676 - accuracy: 0.3995\n",
      "Epoch 00002: val_accuracy improved from 0.11346 to 0.14231, saving model to saved_models/model_5.h5\n",
      "65/65 [==============================] - 46s 710ms/step - loss: 2.0676 - accuracy: 0.3995 - val_loss: 2.9740 - val_accuracy: 0.1423\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 1.3782 - accuracy: 0.5822\n",
      "Epoch 00003: val_accuracy did not improve from 0.14231\n",
      "65/65 [==============================] - 46s 702ms/step - loss: 1.3782 - accuracy: 0.5822 - val_loss: 2.9425 - val_accuracy: 0.1250\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 1.0067 - accuracy: 0.6630\n",
      "Epoch 00004: val_accuracy did not improve from 0.14231\n",
      "65/65 [==============================] - 46s 704ms/step - loss: 1.0067 - accuracy: 0.6630 - val_loss: 2.9216 - val_accuracy: 0.1327\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.7284 - accuracy: 0.7620\n",
      "Epoch 00005: val_accuracy improved from 0.14231 to 0.20385, saving model to saved_models/model_5.h5\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 0.7284 - accuracy: 0.7620 - val_loss: 2.5458 - val_accuracy: 0.2038\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.4592 - accuracy: 0.8418\n",
      "Epoch 00006: val_accuracy improved from 0.20385 to 0.39423, saving model to saved_models/model_5.h5\n",
      "65/65 [==============================] - 46s 711ms/step - loss: 0.4592 - accuracy: 0.8418 - val_loss: 2.0960 - val_accuracy: 0.3942\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.3672 - accuracy: 0.8697\n",
      "Epoch 00007: val_accuracy improved from 0.39423 to 0.40000, saving model to saved_models/model_5.h5\n",
      "65/65 [==============================] - 46s 709ms/step - loss: 0.3672 - accuracy: 0.8697 - val_loss: 2.0528 - val_accuracy: 0.4000\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2812 - accuracy: 0.9101\n",
      "Epoch 00008: val_accuracy improved from 0.40000 to 0.40577, saving model to saved_models/model_5.h5\n",
      "65/65 [==============================] - 47s 720ms/step - loss: 0.2812 - accuracy: 0.9101 - val_loss: 1.8940 - val_accuracy: 0.4058\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2197 - accuracy: 0.9240\n",
      "Epoch 00009: val_accuracy improved from 0.40577 to 0.60385, saving model to saved_models/model_5.h5\n",
      "65/65 [==============================] - 46s 704ms/step - loss: 0.2197 - accuracy: 0.9240 - val_loss: 1.2142 - val_accuracy: 0.6038\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1778 - accuracy: 0.9471\n",
      "Epoch 00010: val_accuracy improved from 0.60385 to 0.60962, saving model to saved_models/model_5.h5\n",
      "65/65 [==============================] - 47s 718ms/step - loss: 0.1778 - accuracy: 0.9471 - val_loss: 1.3281 - val_accuracy: 0.6096\n",
      "Sto salvando\n",
      "17/17 [==============================] - 3s 169ms/step - loss: 1.3281 - accuracy: 0.6096\n"
     ]
    }
   ],
   "source": [
    "VALIDATION_ACCURACY = []\n",
    "VALIDATION_LOSS = []\n",
    "\n",
    "save_dir = 'saved_models/'\n",
    "fold_var = 1\n",
    "\n",
    "for train_index, val_index in skf.split(np.zeros(2602),Y):\n",
    "    training_data = train_data.iloc[train_index]\n",
    "    validation_data = train_data.iloc[val_index]\n",
    "\n",
    "    train_data_generator = idg.flow_from_dataframe(training_data, directory = '../Dataset/Train',\n",
    "                               x_col = \"filename\", y_col = \"label\",\n",
    "                               class_mode = \"categorical\", shuffle = True, color_mode=\"grayscale\",target_size=(224,224),batchsize=32)\n",
    "    valid_data_generator  = idg.flow_from_dataframe(validation_data, directory =  '../Dataset/Train',\n",
    "                            x_col = \"filename\", y_col = \"label\",\n",
    "                            class_mode = \"categorical\", shuffle = True, color_mode=\"grayscale\",target_size=(224,224),batchsize=32)\n",
    "\n",
    "    # CREATE NEW MODEL\n",
    "    model = create_new_model()\n",
    "    # COMPILE NEW MODEL\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"Adam\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    # CREATE CALLBACKS\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+get_model_name(fold_var),\n",
    "                            monitor='val_accuracy', verbose=1,\n",
    "                            save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    # There can be other callbacks, but just showing one because it involves the model name\n",
    "    # This saves the best model\n",
    "    # FIT THE MODEL\n",
    "    history = model.fit(train_data_generator,\n",
    "                epochs=10,\n",
    "                callbacks=callbacks_list,\n",
    "                validation_data=valid_data_generator)\n",
    "    #PLOT HISTORY\n",
    "    #:\n",
    "    #:\n",
    "\n",
    "    # LOAD BEST MODEL to evaluate the performance of the model\n",
    "    model.load_weights(\"saved_models/model_\"+str(fold_var)+\".h5\")\n",
    "    print('Sto salvando')\n",
    "\n",
    "    results = model.evaluate(valid_data_generator)\n",
    "    results = dict(zip(model.metrics_names,results))\n",
    "\n",
    "    VALIDATION_ACCURACY.append(results['accuracy'])\n",
    "    VALIDATION_LOSS.append(results['loss'])\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    fold_var += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4642f6d8-bbb0-4fd6-a9df-ac2ae6f6a42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6461538672447205,\n",
       " 0.6410748362541199,\n",
       " 0.6692307591438293,\n",
       " 0.5799614787101746,\n",
       " 0.6096153855323792]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VALIDATION_ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f25486b8-4f6f-4d3e-bf5e-5f706c012b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0657050609588623,\n",
       " 1.135345697402954,\n",
       " 1.206666350364685,\n",
       " 1.4198025465011597,\n",
       " 1.3281400203704834]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "VALIDATION_LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb528bc5-dc66-4004-a924-ca851e8ada44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}